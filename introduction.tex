\chapter{Introduction}

\section{The need for Verifiable and Succinct System Models}

\subsection*{The role of Formal Methods in Engineering Reliable Systems}
The design and implementation of contemporary software and hardware systems are endeavors of immense complexity. As these systems become increasingly integrated into safety-critical and security-critical domains, from avionics and medical devices to financial networks and autonomous vehicles, the imperative for ensuring their correctness and reliability has grown paramount. In response to this challenge, the field of computer science has developed \textbf{Formal Methods}, a collection of mathematically rigorous techniques and tools for the specification, design, and verification of such systems. The foundational principle of formal methods is that by modeling systems as mathematical entities, one can leverage the power of logic and proof to reason about their behavior with a level of precision and completeness that empirical testing alone cannot achieve \cite{cmu_formal}.

The core value proposition of formal methods lies in their capacity to symbolically examine the entire state space of a design, thereby establishing correctness or safety properties that hold true for all possible inputs and execution scenarios \cite{nasa_what_is_fm}. This rigorous approach can be applied at various points throughout the development lifecycle. In the initial stages, formal specification languages help disambiguate informal requirements, providing a precise, unambiguous blueprint that can guide subsequent development. During design and implementation, formal verification techniques, such as model checking and automated theorem proving, can be used to prove that a system implementation correctly adheres to its specification, uncovering subtle flaws that might otherwise go undetected until late in the process, or even after deployment \cite{cmu_formal}.

Despite their demonstrable power and a growing number of industrial success stories, the widespread adoption of formal methods has been historically hindered by a well-documented "practicality gap". These techniques are often perceived as being too complex, costly in terms of time and resources, and requiring a level of specialized mathematical expertise that is not always available in typical engineering teams. This perception has created a persistent challenge: how to bridge the divide between the theoretical power of formalisms and the practical needs of system engineers. A central theme of this thesis is the direct engagement with this challenge. The research presented herein is driven by the goal of developing formal models that are not only theoretically sound and powerful but also more intuitive, concise, and "readable". By striving for models that are "arguably more readable", this work aims to lower the barrier to entry and make the benefits of formal reasoning more accessible to a broader range of engineering contexts, thereby putting formal methods into wider practice.

\subsection*{Automata Theory as the Bedrock of System Modeling}
Central to the discipline of formal methods is \textbf{Automata Theory}, which provides the fundamental mathematical framework for modeling and analyzing the behavior of computational systems. Automata are abstract machines that serve as formal models of computation, and their study forms a cornerstone of theoretical computer science. Among the various classes of automata, the \textbf{Deterministic Finite Automaton (DFA)} stands out as the canonical model for the class of regular languages. A DFA is formally a tuple $(Q, \Sigma, q_{\text{init}}, \delta, F)$ where $Q$ is a finite set of states, $\Sigma$ is a finite alphabet of input symbols, $q_{\text{init}}$ is the initial state, $\delta$ is a transition function, and $F$ is a set of accepting states. The simplicity and elegance of the DFA model belie its profound importance and wide-ranging applicability. DFAs are fundamental to the theory of computation and have been successfully applied in numerous practical domains, including text processing and pattern matching, the specification and verification of communication protocols, and as the underlying computational engine for many model-checking tools used in software and hardware verification.

A cornerstone of automata theory is the celebrated Myhill-Nerode theorem, which establishes a deep connection between a regular language and its unique minimal-state DFA. The theorem introduces the Nerode equivalence relation, which deems two words equivalent if they are indistinguishable by any suffix. The number of equivalence classes of this relation is precisely the number of states in the smallest possible DFA for the language. This minimal DFA, often called the \textbf{canonical DFA}, is unique up to isomorphism and represents the most state-efficient representation of a regular language within the DFA formalism. This classical result provides a crucial point of reference for this thesis, as one of its key findings will later reveal a surprising and fundamental departure from this principle when considering alternative automaton models.

\subsection*{The Pervasive Challenge: State-Space Explosion}
While DFAs and other finite-state models provide a powerful basis for system verification, their practical application is often severely constrained by a pervasive challenge known as the \textbf{state-space explosion problem}. This problem refers to the exponential growth in the number of states of a model as the number of system components, variables, or concurrent processes increases linearly. For even moderately complex systems, the resulting state space can become astronomically large, quickly overwhelming the memory and computational resources of verification tools and rendering exhaustive analysis infeasible \cite{zuliani_state_explosion}.

The state-space explosion is widely recognized as the primary bottleneck limiting the scalability of automata-based verification techniques, particularly model checking. Consequently, a significant portion of research in formal verification over the past several decades has been dedicated to developing techniques to mitigate its effects. These techniques include, among others, abstraction methods that hide irrelevant detail, partial order reduction for concurrent systems, and symbolic model checking, which uses compact data structures like Ordered Binary Decision Diagrams (OBDDs) to represent vast sets of states and transitions implicitly rather than explicitly \cite{dtic_symbolic_mc}.

Another critical line of attack against this problem, and the one most central to this dissertation, is the development of more succinct modeling formalisms. The goal is to devise new types of automata or specification languages that can represent complex behaviors using significantly fewer descriptive resources (e.g., states, transitions, or symbols) than a traditional DFA. This thesis confronts two distinct but related facets of this combinatorial challenge. The first part addresses the classical state explosion that arises in modeling complex sequential behavior, proposing a new automaton model \cite{DBLP:journals/corr/abs-2410-22761} designed for greater conciseness. The second part tackles the "interleaving explosion"\cite{Keerthan2025netys}, a particularly virulent form of state explosion that occurs when modeling concurrent systems, where the need to account for all possible orderings of asynchronous events leads to a combinatorial blow-up in the model. By addressing both of these challenges, this work seeks to push the boundaries of what can be practically modeled and verified.

\subsection*{Model-Based Testing: A Practical Driver for Succinct Models}
The quest for more succinct and effective formal models is not merely a theoretical pursuit; it is strongly driven by practical engineering needs, particularly in the domain of \textbf{Model-Based Testing (MBT)} \cite{10.1145/1353673.1353681}. MBT is a software testing paradigm where test cases are automatically generated from an abstract, formal model of the System Under Test (SUT) \cite{bs_what_is_mbt}. This approach offers the promise of more systematic and thorough testing with reduced manual effort, enhancing software quality and reliability \cite{rg_survey_mbt_tools}.

The typical MBT workflow involves several key steps \cite{rg_survey_mbt_tools}:
\begin{enumerate}
    \item \textbf{Model Creation:} An engineer develops a formal model (e.g., a state machine, a decision table, or a UML diagram) that captures the desired behavior of the SUT.
    \item \textbf{Test Generation:} A tool automatically derives abstract test cases from the model by applying test selection criteria. These criteria can be based on structural coverage of the model (e.g., covering all states or transitions) or on requirements coverage.
    \item \textbf{Test Concretization and Execution:} The abstract test cases are then translated into concrete, executable test scripts that can be run against the SUT, with the model often providing the oracle to determine pass/fail verdicts.
\end{enumerate}

The effectiveness of the entire MBT process is fundamentally dependent on the quality and tractability of the underlying model. A model that is excessively large, difficult to construct, or hard to understand becomes a significant bottleneck, undermining the potential benefits of automation \cite{10.1145/1353673.1353681}. This creates a powerful, industry-relevant motivation for the research presented in this thesis. The development of formalisms that are more concise and intuitive directly translates into more efficient and effective MBT. A key contribution of this work is the application of its novel automata models to provide a formal semantics for Expressive Decision Tables (EDTs), an industrial specification notation used for test generation, thereby demonstrating a direct and tangible impact on this practical domain.

\section{A Critical Survey of Deterministic Automata Models for Succinctness}
The pursuit of succinctness in automata theory is not new. Over the years, several deterministic models have been proposed to address the verbosity of standard DFAs. To properly situate the contributions of this thesis, it is essential to critically evaluate these existing formalisms and identify the specific research gap that motivates the introduction of a new model. This section provides such a survey, drawing upon the analysis presented in the foundational papers of this work. The evaluation reveals that existing models, while powerful in their own right, make trade-offs that leave a specific niche in the design space unfilled-a niche that the models developed in this thesis are precisely designed to occupy.

\subsection*{Symbolic Automata}
Symbolic automata were introduced primarily to combat the state explosion problem when dealing with systems that operate over large or infinite alphabets, such as the set of all integers or strings. Instead of labeling transitions with individual symbols, symbolic automata use logical predicates or formulas over the input data. For example, a single symbolic transition labeled with a predicate like $x > 100$ can represent an infinite number of concrete transitions for every integer greater than 100. While highly effective for abstracting data, the abstraction provided by symbolic automata is fundamentally data-oriented. They are designed to club together transitions that occur between a fixed pair of states. They do not, however, offer a native mechanism for abstracting over sequences of states or for modeling the high-level behavioral pattern of "waiting for a specific event sequence to occur." Their focus is on the \textit{what} of the input symbol (its properties), not the \textit{when} or in what sequence of multiple, distinct events. This represents a different axis of succinctness, one which symbolic automata do not directly address and which is a primary focus of this thesis.

\subsection*{Generalized and Expression Automata}
A different approach to succinctness involves allowing transitions to be labeled with more complex structures than single symbols, such as strings or regular expressions. This family includes Deterministic Generalized Automata and Deterministic Expression Automata. Deterministic Generalized Automata (DGA) extend DFAs by permitting transitions to be labeled with non-empty strings. A transition $q \xrightarrow{w} q'$ is taken from state $q$ if the remaining input word has the string $w$ as a prefix. This allows a single DGA transition to represent a chain of DFA transitions, effectively "suppressing" the intermediate states. Algorithms exist to derive state-minimal DGAs from DFAs by systematically collapsing such chains. However, the limitation of DGAs lies in their rigid prefix-matching semantics. They cannot "ignore" or "skip over" intermediate parts of the input stream. This makes them ill-suited for specifying behaviors where an action should be triggered by a specific pattern appearing as a \textit{suffix} of the input, regardless of what precedes it. Furthermore, the problem of minimizing DGAs with respect to a more comprehensive total-size metric, which includes the lengths of the string labels, was identified as an open question in prior work \cite{DBLP:journals/corr/abs-2410-22761}.

Deterministic Expression Automata (DEA) generalize this concept further by allowing transitions to be labeled with regular expressions. To maintain determinism, this model imposes two strict constraints on the outgoing transitions from any state: the languages denoted by the regular expression labels must be mutually disjoint, and each of these languages must be \textbf{prefix-free} (meaning no word in the language is a proper prefix of another). While this allows for powerful abstraction, the prefix-free requirement is a significant drawback. It renders DEAs less expressive than standard DFAs, as they are incapable of recognizing many common and useful regular languages that are not prefix-free. This limitation makes them unsuitable as a general-purpose specification formalism.

This critical survey reveals a clear set of trade-offs in existing models. Symbolic Automata abstract data but not control flow sequences. DGAs abstract sequential paths but lack the flexibility to handle non-prefix-based patterns. DEAs offer flexibility but at the cost of reduced expressive power. This analysis carves out a clear vacancy in the design space for a new automaton model that is: (1) fully expressive for all regular languages, (2) deterministic, and (3) provides succinctness by abstracting over input streams in a flexible, pattern-matching manner that is not restricted to prefixes. This thesis introduces \textbf{Deterministic Suffix-Reading Automata} as the precise solution to fill this identified gap.

\section{A New Paradigm: Deterministic Suffix-Reading Automata (DSA)}
In response to the limitations of existing models, this thesis introduces a new formalism: the \textbf{Deterministic Suffix-reading Automaton (DSA)}. This model offers a novel approach to achieving succinctness in deterministic automata by fundamentally altering the mechanism of state transition. It is designed to be fully expressive for all regular languages while providing a more natural and readable way to specify "pattern-intensive" behaviors \cite{DBLP:journals/corr/abs-2410-22761}.

\subsection*{Motivation: From Prefix-Matching to Suffix-Waiting}
The core conceptual innovation of the DSA model is a pivot from the traditional, letter-by-letter processing of automata. A standard DFA implicitly asks, "Given my current state, what do I do with the \textit{next} input symbol?" In contrast, a DSA operates on a higher level of abstraction, effectively asking, "Given my current state, have I \textit{yet seen} an input segment that ends with one of my designated trigger patterns?" This shift from prefix-matching to a "suffix-waiting" paradigm allows the automaton to passively consume long sequences of irrelevant inputs, only becoming active when a meaningful pattern is detected.

This paradigm is powerfully illustrated by the "out-of-context else" example. Consider specifying a language that flags an \texttt{else} statement that appears without a preceding \texttt{if} statement. A DSA for this task can be elegantly designed with just a few states. From an initial state $s_0$, the automaton simply waits. Upon seeing a suffix \texttt{if}, it transitions to a state $s_1$. If it instead sees a suffix \texttt{else} first, it transitions to a final (error) state. From state $s_1$, it again waits for a pattern; seeing \texttt{endif} might return it to a safe state, while seeing another \texttt{if} could indicate a nesting error. This high-level, pattern-based specification is captured directly by the DSA transitions, resulting in a model that is arguably more concise and readable than a corresponding DFA, which would need to meticulously track character-by-character progress towards detecting these keywords.

\subsection*{Formal Definition and Semantics}
Formally, a Deterministic Suffix-reading Automaton (DSA) is a tuple $A = (Q, \Sigma, q_{\text{init}}, \Delta, F)$, where $Q$ is a finite set of states, $\Sigma$ is a finite alphabet, $q_{\text{init}}$ is the initial state, $F$ is a set of accepting states, and $\Delta \subseteq Q \times \Sigma^{+} \times Q$ is a finite set of transitions labeled with non-empty words. For any state $q$, the set of its outgoing transition labels is denoted $\text{Out}(q)$.

The behavior of a DSA is governed by a unique and crucial set of semantic rules that define a move of the automaton. A move is a pair $(t, w)$, where $t = (q, \alpha, q')$ is a transition and $w \in \Sigma^{+}$ is the segment of the input word that triggers it. The move $q \xrightarrow{w/\alpha} q'$ occurs if and only if the following conditions are met:
\begin{enumerate}
    \item \textbf{Suffix-Triggered:} The label $\alpha \in \text{Out}(q)$ is a suffix of the word segment $w$.
    \item \textbf{Earliest Match:} No proper prefix of $w$ has any label in $\text{Out}(q)$ as a suffix. This ensures the automaton acts on the very first occurrence of a recognizable pattern.
    \item \textbf{Longest Match:} The label $\alpha$ is the longest word in $\text{Out}(q)$ that is a suffix of $w$. This rule resolves ambiguity when multiple patterns match simultaneously (e.g., if \texttt{if} and \texttt{endif} are both labels, and the word \texttt{endif} is seen), thereby ensuring the automaton's behavior is deterministic.
\end{enumerate}
A run of a DSA on an input word is a sequence of such moves that partitions the word. The run is accepting if the entire word is consumed and the final state is in $F$.

\subsection*{The Problem of Minimization and the Total-Size Metric}
With the introduction of a new automaton model comes the fundamental question of minimization. For formalisms like DSAs where transitions are labeled with strings of arbitrary length, the traditional metric of simply counting states is an insufficient and potentially misleading measure of the model's complexity or size. A two-state automaton with thousand-character labels is arguably more complex than a ten-state automaton with single-character labels.

To address this, this thesis adopts a more faithful measure of descriptive complexity: the \textbf{total-size} of a DSA. The total-size is formally defined as the sum of the number of states, the number of edges (transitions), and the total length of all transition labels in the automaton. This metric holistically captures the resources needed to describe the automaton. This definition gives rise to the first central problem statement of this dissertation: \textit{Given a regular language L, how can one find an equivalent DSA that is minimal with respect to this total-size metric?} This question motivates a deep investigation into the theoretical properties of DSAs, the development of algorithms to construct them, and an analysis of the computational complexity of finding such minimal representations.

\section{Theoretical Foundations and Fundamental Challenges of DSAs}
Having defined the DSA model, this work undertakes a systematic investigation of its theoretical properties. This exploration establishes the model's expressive power, quantifies its potential for succinctness, develops a constructive method for its creation, and uncovers fundamental challenges related to its minimization. These results, drawn from the first foundational paper, form the theoretical core of the thesis.

\subsection*{Expressiveness and Succinctness}
A primary requirement for any new automaton model intended for general use is that it must be powerful enough to capture the desired class of languages. It is formally established that DSAs recognize exactly the class of regular languages. This is proven by providing a constructive method to convert any given DSA $A$ into an equivalent standard DFA, known as its "tracking DFA," denoted $M_A$. The states of the tracking DFA simulate the behavior of the DSA by keeping track of the longest prefix of an outgoing DSA label that has been seen as a suffix of the input so far. Since every DSA can be converted to a DFA, DSAs do not recognize any non-regular languages. Conversely, since any complete DFA is trivially a DSA, the model is fully expressive for the class of regular languages.

While not increasing expressive power, the primary motivation for DSAs is their potential for succinctness. This potential is formally quantified by Theorem 1 \cite{DBLP:journals/corr/abs-2410-22761}, which establishes bounds on the size of a minimal DSA ($n_S$) relative to the size of the minimal complete DFA ($n_{F_{cmp}}$) for a language:
$$ \frac{n_{F_{cmp}}}{2(1+2|\Sigma|)} \le n_S \le n_{F_{cmp}} $$
This inequality reveals that a DSA can be exponentially smaller than its corresponding minimal DFA, with the degree of compression being particularly significant for languages over large alphabets $|\Sigma|$. A concrete example of this exponential gap is provided by the family of languages $L_n = \Sigma^*a_1...a_n$ over an alphabet $\Sigma$ of size $n$. As shown in Lemma 2 \cite{DBLP:journals/corr/abs-2410-22761}, this language can be recognized by a DSA of linear size, whereas its minimal DFA requires a quadratic number of states and transitions.

\subsection*{Deriving DSAs from DFAs: The Suffix-Tracking Set Method}
To make the DSA model constructive, a method is needed to derive a DSA from a more fundamental representation, such as a DFA. This thesis presents a novel DFA-to-DSA conversion procedure based on the concept of \textbf{suffix-tracking sets}. The intuition is to select a subset of "macro-level" states $S$ from a given complete DFA and effectively "suppress" the intermediate states not in $S$. The transitions of the new DSA are then labeled with the words corresponding to the "simple paths" (acyclic paths whose intermediate states are not in $S$) that connect the chosen macro-states.

For this derivation to be sound-that is, to preserve the language of the original DFA-the chosen set of states $S$ must satisfy two technical conditions:
\begin{enumerate}
    \item \textbf{Suffix-compatible transitions:} This property ensures that the suppressed states collectively behave as a consistent suffix-matcher. It requires that for any path being traced through the suppressed states, every single-step extension leads to a new state that correctly tracks the longest possible suffix pattern.
    \item \textbf{Well-formedness:} This condition prevents ambiguity in the derived DSA. It forbids situations where a simple path leading to a chosen macro-state is a suffix of another simple path that leads to a suppressed state, which would create a conflict in the DSA's transition logic.
\end{enumerate}
A set $S$ that contains the initial and final states and satisfies both of these properties is called a suffix-tracking set. The main constructive result of this part of the work is Theorem 2 \cite{DBLP:journals/corr/abs-2410-22761}, which proves that if $S$ is a suffix-tracking set, the DSA induced by $S$ is guaranteed to be language-equivalent to the original DFA. The full derivation procedure also includes steps for removing certain "useless" transitions from the induced DSA to further improve its conciseness.

\subsection*{A Fundamental Bottleneck: Minimization and the Canonical DFA}
The development of a derivation procedure naturally leads back to the question of minimization. A conventional approach in automata theory would be to apply this procedure to the canonical (minimal-state) DFA of a language, with the expectation of producing a minimal-state or minimal-size version of the new model. However, this thesis presents a "surprising observation" that represents a significant and counter-intuitive departure from this classical principle.

It is demonstrated that the smallest DSA that can be derived from the canonical DFA of a language is not necessarily a minimal DSA for that language. This phenomenon is illustrated with a carefully constructed counterexample in Figures 13 and 14 of the cited work. The example shows that by starting with a larger, non-minimal DFA, it is possible to derive a DSA that is smaller in total-size than any DSA derivable from the canonical DFA.

This discovery carries profound theoretical implications. The Myhill-Nerode equivalence relation, which underpins DFA minimization, partitions the set of all words based on their future behavior in the language. The canonical DFA is the direct embodiment of this equivalence, merging all states that are equivalent in this sense. The finding that this DFA may not yield a minimal DSA suggests that the Nerode equivalence does not capture the right notion of "future equivalence" for the purpose of DSA minimization. A minimal DSA may need to distinguish between two words that are Nerode-equivalent if those words possess different suffix properties that are relevant to the DSA's high-level pattern-matching transitions. The non-minimal DFA in the counterexample provides the "extra" states needed to maintain these finer distinctions about the language's prefix structure, which in turn enables the construction of a more efficient set of DSA transitions. This indicates that for DSA minimization, one might need to consider a richer equivalence relation that accounts for these suffix-based structural properties.

\subsection*{The Intrinsic Complexity of DSA Minimization}
The challenges associated with finding a minimal DSA are not merely procedural; they are rooted in the problem's intrinsic computational complexity. Theorem 5 \cite{DBLP:journals/corr/abs-2410-22761} establishes that the DSA minimization problem is computationally hard: given a DFA, deciding if there exists an equivalent DSA of total-size at most $k$ is \textbf{NP-complete}.

The proof of NP-hardness is achieved via a reduction from the well-known \textbf{Vertex Cover} problem. In this reduction, a DFA is constructed from a graph in such a way that a valid suffix-tracking set in the DFA corresponds directly to a vertex cover in the graph. The total-size of the derived DSA is then carefully linked to the size of the vertex cover. This correspondence proves that an efficient (polynomial-time) algorithm for DSA minimization would imply an efficient algorithm for Vertex Cover, which is widely believed not to exist. This NP-completeness result provides a rigorous justification for the difficulty of the minimization problem. It is not presented as a negative outcome, but rather as a crucial piece of the scientific narrative. It formally demonstrates that an efficient, general-purpose minimization algorithm is highly unlikely to be found. This, in turn, provides strong motivation for the research directions pursued next: the development of effective heuristics and the identification of tractable, restricted subclasses of DSAs for which minimization is feasible.

\subsection*{A Pragmatic Solution: Strong DSAs (SDSAs)}
As a constructive response to the minimization bottleneck and the NP-hardness result, this work introduces a restricted yet powerful subclass of DSAs called \textbf{Strongly Deterministic Suffix-reading Automata (sDSAs)} \cite{Keerthan2024journal}. An sDSA is a DSA that adheres to an additional syntactic constraint on its outgoing labels. Formally, for any state, it is forbidden for a non-trivial prefix of one outgoing label to appear as a suffix of a non-trivial proper prefix of another outgoing label from the same state. Intuitively, this condition prevents certain confusing and potentially ambiguous overlaps between patterns, making the automaton's behavior "strongly" deterministic. This class is shown to be expressive enough to naturally model many practical specifications, such as an automotive alarm system that detects a double press of a panic switch.

The primary significance of the sDSA class lies in its amenability to minimization. The main result for this subclass, Theorem 4 \cite{Keerthan2024journal}, proves that for any language $L$, every minimal sDSA for $L$ can be derived from the canonical DFA for $L$. This remarkable result restores the desirable property that was lost in the general DSA case. It demonstrates that by imposing a reasonable structural constraint, one can define a class of suffix-reading automata that strikes an excellent balance: it is theoretically well-behaved and algorithmically tractable, while remaining sufficiently expressive for practical use.

\section{Bridging the Gap: From Sequential Patterns to Concurrent Systems}
The development of DSAs and sDSAs provides a powerful new toolkit for the succinct specification of sequential, pattern-based systems. However, modern software systems are rarely monolithic and sequential. They are typically composed of multiple interacting components that operate concurrently. This section serves as the crucial narrative pivot of the thesis, motivating the extension of the suffix-reading paradigm from the sequential to the concurrent domain and setting the stage for the contributions of the second foundational paper \cite{Keerthan2025netys}.

\subsection*{The Limits of Sequential Models for Concurrency}
Applying a purely sequential model like a DSA directly to a concurrent system immediately runs into a formidable obstacle: the "interleaving explosion". A concurrent system consists of multiple processes or components that execute asynchronously. To model such a system with a sequential automaton, one must typically account for all possible orderings, or interleavings, of the events generated by the different components. The number of such interleavings grows factorially with the number of events, leading to a combinatorial explosion in the complexity of the model.

This problem is made concrete by the Car Security System example. A practical requirement for starting a car might be that the key is in the ignition (K), the brake pedal is pressed (B), and the transmission is in park (P), with these three actions allowed to occur in any order. A standard DSA, in order to capture this behavior, would be forced to have a transition whose label explicitly enumerates all $3! = 6$ permutations: KBP, KPB, BKP, BPK, PKB, and PBK. This approach completely undermines the goal of conciseness and readability that motivated the DSA model in the first place. As the number of concurrent components grows, this method becomes utterly impractical.

\subsection*{A New Problem: Succinct Specification of Concurrent Suffix-Based Rules}
The failure of the sequential model in the face of concurrency gives rise to the second central problem statement of this thesis: \textit{How can the suffix-reading paradigm be extended to directly and succinctly model specifications that involve combinations of patterns occurring across multiple concurrent components or "ports"?} A natural syntactic approach is to introduce a parallel composition operator, $\parallel$, into the transition labels. Using this operator, the car security requirement could be expressed with a single, elegant transition labeled 'K $\parallel$ B $\parallel$ P'. This syntax would abstract away the interleavings, capturing the logical intent of the specification directly. However, introducing such an operator is not merely a syntactic convenience. The core research challenge lies in defining a formal operational semantics for it that is both theoretically sound and intuitively correct for a wide range of real-world specification scenarios. The development of such a semantics is the primary focus of the next stage of this research.

\section{Multi-Port Suffix-Reading Automata (mDSA) for Specification and Verification}
To address the challenge of specifying concurrent systems, this thesis introduces the \textbf{Multi-port Suffix-reading Automaton (mDSA)}, an extension of the DSA model designed to handle concurrency and outputs. This section presents the key contributions from the second foundational paper, showcasing the evolution of the core concepts to meet the demands of practical, industrial-scale system modeling and verification.

\subsection*{The mDSA Model: Syntax and Semantics of Concurrency}
The mDSA model operates over a multi-port alphabet $\Sigma = \langle\Sigma_1, ..., \Sigma_k\rangle$, where the global alphabet is partitioned among $k$ distinct ports. Transitions are labeled with concurrent patterns like $(u_1 \parallel u_2 \parallel ... \parallel u_k)$, where each $u_i$ is a word (a pattern) from the alphabet of port $i$, $\Sigma_i^*$ \cite{Keerthan2025netys}.

The key innovation of the mDSA model lies in its novel operational semantics, which is defined over a configuration that explicitly manages the system's history. An mDSA configuration is a tuple $(q, w, \Theta)$, where:
\begin{itemize}
    \item $q$ is the current state of the automaton.
    \item $w$ represents the full, persistent history of all input symbols received by the system across all ports, from the beginning of its execution.
    \item $\Theta$ is a numerical marker, or "tape head," indicating the position in the history string $w$ where the last successful transition match occurred.
\end{itemize}
This configuration structure allows for a sophisticated matching rule that resolves a fundamental dilemma in event-based specification. The dilemma, highlighted by contrasting a car security system (which needs to remember that a brake pedal is still pressed) with a smartphone lock (which needs to detect a fresh button press), is whether to consume input history or not. Consuming it loses context, while not consuming it can lead to infinite loops on old data.

The $(q, w, \Theta)$ mechanism elegantly solves this. A concurrent transition $(u_1 \parallel ... \parallel u_k)$ is defined to match a tape configuration $(w, \Theta)$ if two conditions hold:
\begin{enumerate}
    \item \textbf{Suffix Match:} For each port $i$, the pattern $u_i$ must be a suffix of that port's projected history, $P_i(w)$.
    \item \textbf{Freshness Condition:} Critically, at least one of the patterns $u_i$ must have occurred entirely after the marker $\Theta$. That is, its corresponding subword in $w$ must lie completely within $w[\Theta+1, |w|]$.
\end{enumerate}
This marker provides a formal and precise mechanism for capturing the intuitive notion of a "fresh event." It allows the model to check for both persistent conditions (patterns that occurred before $\Theta$) and new trigger events (patterns that occurred after $\Theta$), accommodating both types of specification scenarios within a single, coherent semantic framework.

\subsection*{Putting Theory into Practice: Formalizing Expressive Decision Tables (EDT)}
The development of the mDSA model is not only a theoretical exercise but is also driven by the practical need to formalize existing industrial practices. This is demonstrated through its application to \textbf{Expressive Decision Tables (EDTs)}, a tabular notation used successfully in industry for specifying the requirements of reactive systems. EDTs allow engineers to specify complex, suffix-based rules in a convenient format. For example, a row in an EDT might specify that if the last two inputs on the 'Panic Switch' port were 'Press;Press', an output should be generated on the 'Alarm' port.

Despite their practical success and use in test generation, EDTs have historically lacked a rigorous, formal operational semantics. This gap has meant that test generation tools for EDTs often rely on heuristics and random generation, without the ability to formally prove properties or guarantee coverage. To model the full behavior of EDTs, which includes not just input conditions but also the generation of output actions, the mDSA model requires one final extension: the ability to produce outputs. This practical requirement directly motivates the development of \textbf{mDSAs-with-outputs}.

\subsection*{mDSAs-with-Outputs and the Emergence of New Complexity}
The final evolution of the model, the mDSA-with-outputs, extends transitions to include an output part. A transition can now specify that upon matching an input condition, a set of output symbols should be produced. These outputs are atomically appended to the end of the history tape $w$. This seemingly small extension has profound consequences. It creates a powerful feedback loop where the automaton can modify its own history, and these modifications can, in turn, be immediately consumed by the input conditions of subsequent transitions. This transforms the automaton from a passive language recognizer into an active computational device. The main theoretical result for this final model reveals the depth of this transformation: state reachability for mDSAs-with-outputs is proven to be \textbf{PSPACE-complete} \cite{Keerthan2025netys}.

The source of this high computational complexity is vividly illustrated using the N-bit counter example. This example shows how a polynomially-sized mDSA-with-outputs can use the input-output feedback loop to simulate a binary counter. The state of the counter is not stored in the automaton's finite state control but is instead encoded on the history tape $w$. Each increment of the counter is performed by a transition that reads the current bits from the tape and writes the new bits back to the tape. To reach the final state of the counter requires a number of steps exponential in the number of bits (N). This demonstrates that a witness for reachability can be exponentially long, leading to the PSPACE complexity class.

This entire development arc perfectly embodies the title of this dissertation, "Putting Practice into Theory (and Back)." The practical need to provide a formal semantics for an industrial notation (EDT) led to a theoretical model extension (mDSAs-with-outputs). The formal analysis of this new theoretical model, in turn, revealed a deep and fundamental complexity result (PSPACE-completeness). This theoretical discovery then feeds back to practice, providing a formal explanation for the inherent difficulty of test generation for EDT-like specifications and informing the design of future verification tools.

\section{Thesis Outline and Contributions}
This dissertation introduces and analyzes a new family of automata, Suffix-Reading Automata, designed to provide succinct and readable formal models for sequential and concurrent systems. The research bridges the gap between automata theory and engineering practice by developing formalisms that are both theoretically deep and practically motivated.

\subsection*{Summary of Contributions}
The primary contributions of this dissertation can be summarized as follows:
\begin{itemize}
    \item \textbf{Contribution 1 (A New Model for Sequential Specifications):} The introduction of the Deterministic Suffix-reading Automaton (DSA) as a novel, fully expressive, and deterministic formalism for regular languages. This model provides a more succinct and readable representation for pattern-intensive specifications compared to traditional DFAs. A complete theoretical analysis of its properties, including a DSA-to-DFA conversion via the "tracking DFA" construction, is provided.
    \item \textbf{Contribution 2 (Deepening the Theory of Automata Minimization):} The discovery of a fundamental bottleneck in DSA minimization, demonstrating that the canonical (Myhill-Nerode) DFA is insufficient for deriving minimal DSAs. This is complemented by a formal proof that the DSA minimization problem is NP-complete. As a constructive solution, the Strong DSA (sDSA) subclass is introduced, which is shown to be a tractable and well-behaved class for which minimal automata are derivable from the canonical DFA.
    \item \textbf{Contribution 3 (A New Model for Concurrent Specifications):} The extension of the suffix-reading paradigm to concurrent systems with the Multi-port DSA (mDSA) model. This model features an innovative tape-based semantics with a history marker ($(q, w, \Theta)$) that correctly and elegantly formalizes the management of event history and the notion of "freshness" required for triggering concurrent transitions.
    \item \textbf{Contribution 4 (Bridging Formalism and Industrial Practice):} The development of the first formal operational semantics for a significant fragment of the industrial Expressive Decision Table (EDT) notation, achieved via a translation to mDSAs-with-outputs. The subsequent proof that the associated test generation problem (state reachability) is PSPACE-complete reveals the deep computational complexity inherent in such practical specification languages, demonstrating a full cycle from practice to theory and back again.
\end{itemize}

\subsection*{Thesis Structure}
The remainder of this dissertation is organized as follows:
\begin{itemize}
    \item \textbf{Chapter 2: Preliminaries and A Survey of Automata Models:} This chapter will formally define the foundational concepts from automata theory and formal methods that are used throughout the thesis. It will also present the detailed critical survey of related automata models discussed in Section 2 of this introduction.
    \item \textbf{Chapter 3: Deterministic Suffix-Reading Automata (DSA):} This chapter will present the formal definition, semantics, and complete theoretical analysis of the DSA model. This includes the tracking DFA construction, proofs of expressiveness, and the succinctness results.
    \item \textbf{Chapter 4: Derivation and Minimization of DSAs:} This chapter will detail the DFA-to-DSA derivation procedure via suffix-tracking sets. It will present the counterexample demonstrating the canonical DFA bottleneck, the full NP-completeness proof for minimization, and the complete theory of Strong DSAs (sDSAs).
    \item \textbf{Chapter 5: Multi-Port Suffix-Reading Automata (mDSA):} This chapter will introduce the mDSA model for specifying concurrent systems. It will detail the multi-port alphabet, the $\parallel$ operator, the innovative tape-based semantics, and the extension to mDSAs-with-outputs.
    \item \textbf{Chapter 6: Application to Expressive Decision Tables and Complexity of Reachability:} This chapter will present the translation from the EDT notation to mDSAs-with-outputs, thereby providing EDTs with a formal semantics. It will then present the full proof of PSPACE-completeness for the state reachability problem and discuss the practical implications of this result for model-based testing.
    \item \textbf{Chapter 7: Conclusion and Future Work:} This chapter will summarize the key findings of the dissertation and discuss several promising directions for future research. These include the development of scalable algorithms and heuristics for mDSA reachability, the investigation of learning algorithms for DSAs from examples, and the extension of the suffix-reading paradigm to incorporate real-time constraints.
\end{itemize}

